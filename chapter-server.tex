\chapter{Development of a Web Application Programming Interface for Genome Properties Data}

A very common delivery mechanism for data analysis software is via the World Wide Web and in the form of a web application. In such implementations, users connect to a remote server computer system \footnote{The term server is used interchangeably for a verity of concepts. For this document we use the term \textbf{server computer system} to refer to the physical hardware where server software is run. The term \textbf{server} is used to refer to a software process which provides users and applications with data. A server process may provide data directly to other processes running on the same server computer system or provide data over a network in response to a remote procedure call (RPC) cite (XXX).} via their web browser and download the code for the application. The application is then run within this browser. Such applications follow a client-server architecture (cite XXX) where the code running in the user's browser is called the client. If the client requires external data it can request this information from server process running on the server computer system from which it was downloaded or from a third party server computer system, if given permission. Clients can request a variety of information types from a server, including images, videos, files and stored data. This stored data most often returned to the client in JSON format (cite XXX). A common technique used by web clients for contacting a server is Asynchronous JavaScript and XML (AJAX) \cite{XXX} (see \href{}{}). AJAX allows for client web applications to make requests to a server, using JavaScript (cite XXX), without the need for a web page reload. This technique allows for the development of asynchronous client applications are not kept in sync with the server they were downloaded from. AJAX requests data from a server, via Hypertext Transfer Protocol (HTTP), through a series of Uniform Resource Locator (URL) addresses, or web addresses, which return data of specific types. These addresses are known as endpoints (Section XXX) and form an web Application Programming Interface (API) cite{} for which web clients can request information.

As discussed in Chapter XXX, Micromeda's Genome Properties visualization application consists of two components: A client web application and server process. In this chapter we will discuss the sever component in detail, including the endpoints it provides and its implementation. In the following chapter we discuss the client web applications which uses these endpoints. We call this server component Micromeda-Server

\section{Micromeda Server Workflow and Implementation}

Micromeda server is designed to provide a web API to client applications which require access to information about the Genome Properties database. It also provides an API for accessing temporarily stored property assignments, step assignments and supporting information for user supplied datasets. Information about the genome properties database is supplied to Micromeda-Server via a \textbf{genomeProperties.txt} file stored on the server computer system it's running on. Property assignments, step assignments and supporting information for user datasets are supplied via user uploaded Micromeda files. These Micromeda files are parsed into GenomePropertyResultsWithMatches objects which are later stored in an in-memory Redis cache \footnote{Redis (citeXXX) is an server process which provides a in-memory key-value store with hard-disk back-up. It allows for the caching of datasets in RAM. Each value stored can later be retrieved from Redis using a key provided to Redis during caching. A Redis server can be accessed by processes running adjacent server computer systems. It can also be set up in a distributed cluster configuration across several server computer systems for redundancy and availability. Redis was chosen over competing caching servers such as Memcached (cite xx) do to its ability to handle larger MessagePack binaries and ability to back-up data to disk. Disk backup is important as it allows for the safe storage of datasets overtime and across high traffic volumes where the server may have ran out of RAM is Memcached was used.} in MessagePack format. A single Micromeda file can also be stored on the server computer system and used as default dataset for Micromeda server. This default dataset is used to supply data to the API if no Micromeda files are uploaded by users. The standard workflow for starting and using Micromeda-Server is the following:

\begin{enumerate}
  \item Start Micromeda server while providing a \textbf{genomeProperties.txt} file and am optional default dataset Micromeda file
  \item The \textbf{genomeProperties.txt} file is parsed to a GenomePropertiesTree object
  \item The default dataset Micromeda file is parsed to a GenomePropertiesResultsWithMatches object
  \item The client application sends a user supplied Micromeda file to the server via the upload endpoint
  \item The user supplied Micromeda files is parsed to a GenomePropertiesResultsWithMatches object which is later stored in the Redis cache in MessagePack format
  \item The server supplies the client with a dataset key which is unique to each uploaded Micromeda file
  \item The client can later supply this dataset key to the server during API requests to get information from previously uploaded Micromeda files
  \item If no dataset key is provided by the client then the server supplies information about the default dataset during API requests
\end{enumerate}

Each GenomePropertiesResultsWithMatches object cached to Redis is given a Time To Live (TTL) value. This value can be set to any time period such as minutes or days. After the TTL of the cached object is exceeded, it is flushed from the cache and the user will have to re-upload their Micromeda file. The default TTL used is two hours. During each API request, if a dataset key is provided, the MessagePack formatted GenomePropertiesResultsWithMatches object is grabbed from the cache and reconstituted into its original form. During the API call this reconstituted GenomePropertiesResultsWithMatches object's method are used to supply data to the client. Further details on these endpoints are provided in Section \ref{endpoints}.

\section{Use of Redis for Dataset Caching}

Python, due to limitations in its default interpreter, is only capable executing one thread at a time. This causes problems for server web APIs which are required to handle multiple requests simultaneously. In response, the majority of Python web frameworks, which provide boilerplate code for writing endpoints, are designed to run multiple copies of the Python script which handles endpoint requests. These scripts are run in separate processes and do not share memory spaces. Thus any objects data created in one of these processes is not shared with the others. Also there is no guarantee that API request from a single web client will be repeatedly mapped to the same API server process. This lack of mapping causes problems as the object created for one client, for example a GenomePropertiesResultsWithMatches object created from the upload of a Micromeda file, would only be stored in one process and would not be available in other process that future client requests may be directed too. One way of getting around this process isolation issue is to store data that needs to be shared between web server processes in an external process which is used to cache. This way the web API process have one place to call to get their shared data. In the case of Micromeda's server process we chose to use Redis as this caching process. Redis is a caching server that stores keyed data RAM. It also can be given memory use limits and will store store a portion of its data on disk. Micromeda's server use Redis to cache GenomePropertiesResultsWithMatches objects, in MessagePack format, for use by its many request handling processes. These GenomePropertiesResultsWithMatches objects are generated from Micromeda files uploaded to the server. During API requests where the client wants data from a specific dataset, Micromeda's serve process pull MessagePack formatted GenomePropertiesResultsWithMatches objects from the Redis cache, reconstitute them and use their methods to gather data for the request. The very fast speed of serialization and deserialization of MessagePack to and from GenomePropertiesResultsWithMatches objects allows for this data-flow with minimal performance penalties.

\section{Application Programming Interface Endpoints} \label{endpoints}

Micromeda server provides several endpoints for supplying web clients with information about individual genome properties and information from uploaded Micromeda files. These endpoints and their implementation are summarized in Table \ref{tab:endpoints} and detailed in subsections below.

\begin{longtable}{|p{1.6cm}|p{2.5cm}|p{1.4cm}|p{2.2cm}|p{2.2cm}|p{4cm}|}
\caption{Micromeda's server component provides web applications with five endpoints where they can request data about individual genome properties, upload Micromeda files and request information about stored assignment databases.}
\label{tab:endpoints}\\
\hline
\textbf{Python Function Name} & \textbf{Endpoint URL} & \textbf{HTTP Request Types} & \textbf{URL Path Variables} & \textbf{GET Parameter Variables} & \textbf{Return Value} \\ \hline
\endfirsthead
%
\multicolumn{6}{c}%
{{\bfseries Table \thetable\ continued from previous page}} \\
\hline
\textbf{Python Function Name} & \textbf{Endpoint URL} & \textbf{HTTP Request Types} & \textbf{URL Path Variables} & \textbf{GET Parameter Variables} & \textbf{Return Value} \\ \hline
\endhead
%
upload & /upload & GET, POST & None & None & JSON containing a dataset key that can be used in future requests to access information from the uploaded Micromeda file \\ \hline
get\_tree & /genome \_properties \_tree & GET & None & dataset\_key (optional) & A JSON tree representing all properties in the current Genome Properties database with each node annotated with a list of YES, NO, PARTIAL assignments for each sample \\ \hline
get\_single \_genome \_property \_info & /genome \_properties/ \textless{}string: property\_id\textgreater{} & GET & property\_id & None & JSON containing information about a genome property such as a description and a list of equivalent records from other databases (e.g. KEGG, MetaCyc) \\ \hline
get \_multiple \_genome \_property \_info & /genome \_properties & GET & None & None & A JSON array containing information about all genome properties in the database. Each property is given a description and a list of equivalent records from other databases (e.g. KEGG, MetaCyc) \\ \hline
get\_fasta & /fasta/ \textless{}string: property\_id\textgreater{}/ \textless{}int:step \_number\textgreater{} & GET & property\_id, step\_number & dataset\_key (optional), top (optional) & A FASTA file containing either all or the top proteins (i.e., those with lowest E-value domain annotation) supporting the existence of a given property step of a given dataset \\ \hline
\end{longtable}

\subsection{The Upload Endpoint} \label{endpoint-upload}

This API endpoint accepts the client upload of a Micromeda file and returns a hexadecimal encoded universally unique identifier (UUID) key which can be used by future API calls to request information from the uploaded Micromeda file. After upload the Micromeda file is parsed and transformed into a GenomePropertiesResultsWithMatches object. This object is then serialized to MessagePack using the object's \textbf{to\_msgpack} function and the resulting binary is cached in a Redis RAM cache using the Redis Python library. During the previous process a UUID, to be used as a dataset key, is generated using Python's builtin UUID generation function. This UUID is used as the key for the MessagePack serialization stored in the Redis cache. It is also returned to the client application in response to the file upload. The client can provide this key to other API endpoints to receive data from the uploaded Micromeda file. 

\subsection{The Get\_Tree Endpoint}

The Get\_Tree endpoint provides the client with a JSON tree representing all properties and steps in Genome Properties database. This tree represents parent-child relationships between properties. Step nodes are also and to the parent genome properties and act as leaves. Notes that this endpoint returns a tree not a DAG (Fig XXX). In this tree, properties which would have had two parents in the Genome Properties DAG (ref XXX) are duplicated (fig XXX). Each property and step node in the tree is annotated by a list of assignments of support (i.e., YES, NO, PARTIAL), one for each sample in an previously uploaded or default Micromeda file (fig XXX). The Get\_Tree endpoint can take a \textbf{dataset\_key} HTTP GET request variable. If a dataset key generated by the previous upload of Micromeda file is assigned to this variable, then the assignments of support stored in the key's associated Micromeda file are used. The dataset key is used to reconstitute GenomePropertiesResultsWithMatches, representing the uploaded Micromeda file, from the Redis cache. The GenomePropertiesResultsWithMatches object's \textbf{to\_json} method (Table XXX) is called generate the above tree JSON returned from the request. If no dataset\_key is provided, GenomePropertiesResultsWithMatches object of the default Micromeda is used to generate the tree JSON using the same method.

\subsection{The Get\_Single\_Genome\_Property\_Info Endpoint}

The Get\_Single\_Genome\_Property\_Info endpoint takes a genome property identifier as a URL parameter. This genome property identifier is then used query for a representative GenomeProperty object from the GenomePropertiesTree object created on server start (Section XXX). If found this GenomeProperty object's \textbf{to\_json} method (Table XXX) is used to create the property information JSON that is returned from this endpoint.

\subsection{The Get\_Multiple\_Genome\_Property\_Info Endpoint}

When the The Get\_Multiple\_Genome\_Property\_Info endpoint is called, the \textbf{to\_json} method is called for every GenomeProperty object of the GenomePropertiesTree object created on server start and each of the JSON strings generated are to a list in a single larger JSON document which was returned as this endpoints response. 

\subsection{The Get\_Fasta Endpoint}

The Get\_Fasta endpoint is used to send the client FASTA files containing protein sequences which support the existence of property steps across multiple organisms in a dataset. This file can either contain all proteins which support the existence of a step or only those whose domain annotations have the lowest E-value for a domain which supports the existence of a property step. The contents of the file is control by a presence of a HTTP GET variable called top in the request being set to true. Like the  Get\_Tree this endpoint also accepts a dataset\_key variable. The value this variable is also used to reconstitute a GenomePropertiesResultsWithMatches object representing an uploaded Micromeda file. This object's \textbf{write\_supporting\_proteins\_for\_step\_fasta} function (Table XXX) is used generate the FASTA file which is returned to the client. The request to endpoint's genome property identifier and step number URL variables as well as the above top HTTP GET variable are passed to this function during processing of the request.

\section{Micromeda Server Performance}

\section{Micromeda Server Deployments}

\section{Future Improvements}
